{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d085695f",
   "metadata": {},
   "source": [
    "# Generative Setting (CWGAN-GP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c060c327",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1954e9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Dense, concatenate, Input\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy.stats import wasserstein_distance\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import wasserstein_distance\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# define model architecture : 1DCNN-classification\n",
    "from keras.layers import Input,concatenate\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3b915f",
   "metadata": {},
   "source": [
    "## Case study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dc50f0",
   "metadata": {},
   "source": [
    "The case study consists of a 6-storey metal tower, monitoring the displacements at each of the 6 storeys (d1, d2, d3, d4, d5, d6), the force applied to the tower (F), and the time of damage since the bolts loosening began (t)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928938ce",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb3301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All variables ##\n",
    "\n",
    "j = 1                  #trial number\n",
    "epoch_num = 8          # total epoch to run\n",
    "BATCH_SIZE = 100       # batch size of train set\n",
    "noise_dim = 25         # dimension of noise vector for generator\n",
    "condition_dim = 6      # dimension of condition vector for generator\n",
    "gen_dim = 8            # dimension of generator's output vector\n",
    "D_cycle = 5            # train disctriminator \"D_cycle\" times in one epoch, number of critic iterations per epoch\n",
    "steps_show = 1         # update figure per \"steps_show\" epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf52bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = shuffle(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c1bd6b",
   "metadata": {},
   "source": [
    "\"inp\" = \"input\" = \"condition\" = (label1, label2, label3, label4, label5, label6) \n",
    "\n",
    "\"out\" = \"output\" = \"target\" = (d1,d2,d3,d4,d5,d6,F,t)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = dataframe[['label1','label2','label3','label4','label5','label6']]\n",
    "inp=np.array(inp, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896c712",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dataframe[['d1','d2','d3','d4','d5','d6','F', 't']]\n",
    "out=np.array(out, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48194fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_real = tf.concat([inp, out], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "out_scaled = scaler.fit_transform(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b0429",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e645f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.concat([inp, out_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd39e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(data[:,:]).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c9770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_condition = Input(shape=[condition_dim, 1], name='condition_G')\n",
    "inp_noise = Input(shape=[noise_dim, 1], name='noise')\n",
    "X = concatenate([inp_condition, inp_noise], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca2253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generator and Discriminator ##\n",
    "def Generator():\n",
    "    inp_condition = Input(shape=[condition_dim,1 ], name='condition_G')\n",
    "    inp_noise = Input(shape=[noise_dim,1 ], name='noise')\n",
    "    X = concatenate([inp_condition, inp_noise], axis=1)\n",
    "    \n",
    "    X = Conv1D(filters = 32, kernel_size = 3)(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling1D(pool_size=2)(X)\n",
    "    \n",
    "    X = Conv1D(filters = 32, kernel_size = 3)(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling1D(pool_size=2)(X)\n",
    "         \n",
    "    X = Conv1D(filters = 32, kernel_size = 2)(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling1D(pool_size=2)(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    X = Dense(64, activation='relu')(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "    X = Dense(32, activation='relu')(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "    \n",
    "    last = Dense(gen_dim, activation=\"tanh\")(X)\n",
    "    return tf.keras.Model(inputs=[inp_condition, inp_noise], outputs=last, name='Generator')\n",
    "    \n",
    "def Discriminator():\n",
    "    inp_condition = Input(shape=[condition_dim, 1], name='condition_D')\n",
    "    inp_target = tf.keras.layers.Input(shape=[gen_dim,1], name='target')\n",
    "    X = concatenate([inp_condition, inp_target], axis=1)\n",
    "        \n",
    "    X = Conv1D(filters = 32, kernel_size = 3)(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "    X = Activation('LeakyReLU')(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "    \n",
    "    X = Conv1D(filters = 32, kernel_size = 3)(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "    X = Activation('LeakyReLU')(X)\n",
    "    #X = Dropout(0.3)(X)\n",
    "           \n",
    "    X = Conv1D(filters = 32, kernel_size = 2)(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "    X = Activation('LeakyReLU')(X)\n",
    "    #X = Dropout(0.3)(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "        \n",
    "    last = Dense(1)(X)\n",
    "    return tf.keras.Model(inputs=[inp_condition, inp_target], outputs=last, name='Discriminator')   \n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "generator.summary()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dec56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generator loss and Discriminator loss ##\n",
    "lambda_reg = 10  #0.5,  Gradient penalty coefficient (Î»)\n",
    "def discriminator_loss(D_real, D_fake, penalty):\n",
    "    D_loss = tf.reduce_mean(D_fake - D_real + lambda_reg * penalty)\n",
    "    return D_loss\n",
    "\n",
    "def generator_loss(D_fake):\n",
    "    G_loss = -tf.reduce_mean(D_fake)\n",
    "    return G_loss\n",
    "\n",
    "## Optimizers ##\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5, beta_2=0.9) #1e-3, beta_1=0.5, beta_2=0.9\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5, beta_2=0.9)\n",
    "\n",
    "## Gradient penalty to the Discriminator loss ##\n",
    "def penalty_calculation(X_real, G_fake, condition):\n",
    "    # Create the gradient penalty operations.\n",
    "    epsilon = tf.random.uniform(shape=tf.shape(X_real), minval=0., maxval=1.)  #minval=0., maxval=1.\n",
    "    interpolation = epsilon * X_real + (1 - epsilon) * G_fake\n",
    "    with tf.GradientTape() as pena_tape:\n",
    "        pena_tape.watch(interpolation)\n",
    "        penalty = (tf.norm(\n",
    "            pena_tape.gradient(discriminator([condition, interpolation]), interpolation),\n",
    "            axis=1) - 1) ** 2.0\n",
    "    return penalty\n",
    "\n",
    "## Train Generator and Discriminator independently  ##\n",
    "@tf.function\n",
    "def train_G(data_batch):\n",
    "    noise = tf.random.normal([data_batch.shape[0], noise_dim], mean=0.0, stddev=0.1, #stddev=1.0\n",
    "                             dtype=tf.dtypes.float32)\n",
    "    condition = data_batch[:, :condition_dim]                                   \n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        G_fake = generator([condition, noise], training=True)\n",
    "        D_fake = discriminator([condition, G_fake], training=True)\n",
    "        G_loss = generator_loss(D_fake)\n",
    "    gradients_of_generator = gen_tape.gradient(G_loss, generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    return G_loss\n",
    "\n",
    "@tf.function\n",
    "def train_D(data_batch):\n",
    "    noise = tf.random.normal([data_batch.shape[0], noise_dim], mean=0.0, stddev=0.1, #stddev=1.0\n",
    "                             dtype=tf.dtypes.float32)\n",
    "    condition = data_batch[:, :condition_dim]                                   \n",
    "    target = data_batch[:, condition_dim :condition_dim + gen_dim]                                       \n",
    "    with tf.GradientTape() as disc_tape:\n",
    "        G_fake = generator([condition, noise], training=True)\n",
    "        D_real = discriminator([condition, target], training=True)\n",
    "        D_fake = discriminator([condition, G_fake], training=True)\n",
    "        penalty = penalty_calculation(target, G_fake, condition)\n",
    "        D_loss = discriminator_loss(D_real, D_fake, penalty)\n",
    "    gradients_of_discriminator = disc_tape.gradient(D_loss, discriminator.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    return D_loss\n",
    "\n",
    "\n",
    "def train(dataset, epochs, D_cycle=D_cycle, steps_show=steps_show):          #D_cycle=1\n",
    "    start = time.time()\n",
    "    \n",
    "    loss_G_train = []\n",
    "    loss_D_train = []\n",
    "    for epoch in range(epochs):\n",
    "        for data_batch in dataset:\n",
    "            G_loss = train_G(data_batch)\n",
    "            for _ in range(D_cycle):\n",
    "                D_loss = train_D(data_batch)\n",
    "\n",
    "        loss_G_train.append(G_loss.numpy())\n",
    "        loss_D_train.append(D_loss.numpy())\n",
    "\n",
    "        num_test = num_first\n",
    "        condition = data[:num_test, :condition_dim]                         \n",
    "        noise = tf.random.normal([num_test, noise_dim], mean=0.0, stddev=0.1, dtype=tf.dtypes.float32)  #stddev=1.0\n",
    "        generated_out = generator([condition, noise], training=True)\n",
    "\n",
    "        generated_out_final = scaler.inverse_transform(generated_out)\n",
    "\n",
    "\n",
    "        tiempo = time.time() - start\n",
    "\n",
    "        minutos = int(tiempo // 60)\n",
    "        segundos = int(tiempo % 60)\n",
    "\n",
    "        #print(f\"Minutos: {minutos}\")\n",
    "        #print(f\"Segundos: {segundos}\")\n",
    "        print('Time for epoch {}/{} is {} sec, {} minutos y {} segundos'.format(epoch, epochs, time.time() - start, minutos, segundos ))\n",
    "\n",
    "    return loss_G_train, loss_D_train, generated_out_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b83f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_G_train, loss_D_train, generated_out_final = train(train_dataset, epochs=epoch_num, D_cycle=D_cycle, steps_show=steps_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9513a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('Models/CWGAN_'+str(j))\n",
    "print('Model saved in Models/CWGAN_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179ae7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = data[:, :condition_dim]\n",
    "data_generated = np.concatenate([condition.numpy(), generated_out_final], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_generated=pd.DataFrame(data_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99ade95",
   "metadata": {},
   "source": [
    "# Training visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eddcbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "\n",
    "condition = data[:, :condition_dim]                       \n",
    "           \n",
    "fontsize = 8\n",
    "    \n",
    "list_limx = [[0, .055], [0, .055], [0, .055], [0, .055], [0, .055], [0, .055], [0, .055]]\n",
    "#list_limy = [[0, 100], [0, 450], [-0.1, 1.1], [-0.1, 1.1]]\n",
    "figure, ax = plt.subplots(1, 7, figsize=(15, 3))\n",
    "figure.suptitle(\"Conditional GAN (CWGAN-GP)\")\n",
    "sns.set(color_codes=True, style='white', palette='colorblind')\n",
    "          \n",
    "### d1  -  label1  ###\n",
    "i = 0\n",
    "ax[i].clear()\n",
    "ax[i].set_xlim(list_limx[i])\n",
    "ax[i].set_xlabel('d1 (mm)')\n",
    "ax[i].set_ylabel('label1')\n",
    "plot_data_real= data_real.numpy()[:num_test, :]                \n",
    "ax[i].plot(plot_data_real[:num_test, 7], plot_data_real[:num_test, 0], '.b', alpha=.5, label=\"Real\")\n",
    "ax[i].yaxis.set_major_locator(plt.MultipleLocator(base=1)) \n",
    "ax[i].yaxis.set_major_formatter('{:.0f}'.format)  \n",
    "plot_data_generated = dataframe_generated.values\n",
    "ax[i].plot(plot_data_generated[:num_test, 7], plot_data_generated[:num_test, 0]+0.05, '.r', alpha=.5, label=\"Generated\")\n",
    "ax[i].legend(loc='center right', fontsize=fontsize)\n",
    "plt.subplots_adjust(wspace=0.5)  \n",
    "                                \n",
    "### d2  -  label2  ###\n",
    "i = 1\n",
    "ax[i].clear()\n",
    "ax[i].set_xlim(list_limx[i])\n",
    "ax[i].set_xlabel('d2 (mm)')\n",
    "ax[i].set_ylabel('label2')\n",
    "plot_data_real= data_real.numpy()[:num_test, :]                \n",
    "ax[i].plot(plot_data_real[:num_test, 8], plot_data_real[:num_test, 1], '.b', alpha=.5, label=\"Real\")\n",
    "ax[i].yaxis.set_major_locator(plt.MultipleLocator(base=1)) \n",
    "ax[i].yaxis.set_major_formatter('{:.0f}'.format)  \n",
    "plot_data_generated = dataframe_generated.values\n",
    "ax[i].plot(plot_data_generated[:num_test, 8], plot_data_generated[:num_test, 1]+0.05, '.r', alpha=.5, label=\"Generated\")\n",
    "ax[i].legend(loc='center right', fontsize=fontsize)\n",
    "plt.subplots_adjust(wspace=0.5)     \n",
    "\n",
    "### d3  -  label3  ###\n",
    "i = 2\n",
    "ax[i].clear()\n",
    "ax[i].set_xlim(list_limx[i])\n",
    "ax[i].set_xlabel('d3 (mm)')\n",
    "ax[i].set_ylabel('label3')\n",
    "plot_data_real= data_real.numpy()[:num_test, :]                \n",
    "ax[i].plot(plot_data_real[:num_test, 9], plot_data_real[:num_test, 2], '.b', alpha=.5, label=\"Real\")\n",
    "ax[i].yaxis.set_major_locator(plt.MultipleLocator(base=1)) \n",
    "ax[i].yaxis.set_major_formatter('{:.0f}'.format)  \n",
    "plot_data_generated = dataframe_generated.values\n",
    "ax[i].plot(plot_data_generated[:num_test, 9], plot_data_generated[:num_test, 2]+0.05, '.r', alpha=.5, label=\"Generated\")\n",
    "ax[i].legend(loc='center right', fontsize=fontsize)\n",
    "plt.subplots_adjust(wspace=0.5)     \n",
    "\n",
    "### d4  -  label4  ###\n",
    "i = 3\n",
    "ax[i].clear()\n",
    "ax[i].set_xlim(list_limx[i])\n",
    "ax[i].set_xlabel('d4 (mm)')\n",
    "ax[i].set_ylabel('label4')\n",
    "plot_data_real= data_real.numpy()[:num_test, :]                \n",
    "ax[i].plot(plot_data_real[:num_test, 10], plot_data_real[:num_test, 3], '.b', alpha=.5, label=\"Real\")\n",
    "ax[i].yaxis.set_major_locator(plt.MultipleLocator(base=1)) \n",
    "ax[i].yaxis.set_major_formatter('{:.0f}'.format)  \n",
    "plot_data_generated = dataframe_generated.values\n",
    "ax[i].plot(plot_data_generated[:num_test, 10], plot_data_generated[:num_test, 3]+0.05, '.r', alpha=.5, label=\"Generated\")\n",
    "ax[i].legend(loc='center right', fontsize=fontsize)\n",
    "plt.subplots_adjust(wspace=0.5)  \n",
    "\n",
    "### d5  -  label5  ###\n",
    "i = 4\n",
    "ax[i].clear()\n",
    "ax[i].set_xlim(list_limx[i])\n",
    "ax[i].set_xlabel('d5 (mm)')\n",
    "ax[i].set_ylabel('label5')\n",
    "plot_data_real= data_real.numpy()[:num_test, :]                \n",
    "ax[i].plot(plot_data_real[:num_test, 11], plot_data_real[:num_test, 4], '.b', alpha=.5, label=\"Real\")\n",
    "ax[i].yaxis.set_major_locator(plt.MultipleLocator(base=1)) \n",
    "ax[i].yaxis.set_major_formatter('{:.0f}'.format)  \n",
    "plot_data_generated = dataframe_generated.values\n",
    "ax[i].plot(plot_data_generated[:num_test, 11], plot_data_generated[:num_test, 4]+0.05, '.r', alpha=.5, label=\"Generated\")\n",
    "ax[i].legend(loc='center right', fontsize=fontsize)\n",
    "plt.subplots_adjust(wspace=0.5)  \n",
    "\n",
    "### d6  -  label6  ###\n",
    "i = 5\n",
    "ax[i].clear()\n",
    "ax[i].set_xlim(list_limx[i])\n",
    "ax[i].set_xlabel('d6 (mm)')\n",
    "ax[i].set_ylabel('label6')\n",
    "plot_data_real= data_real.numpy()[:num_test, :]                 \n",
    "ax[i].plot(plot_data_real[:num_test, 12], plot_data_real[:num_test, 5], '.b', alpha=.5, label=\"Real\")\n",
    "ax[i].yaxis.set_major_locator(plt.MultipleLocator(base=1)) \n",
    "ax[i].yaxis.set_major_formatter('{:.0f}'.format)  \n",
    "plot_data_generated = dataframe_generated.values\n",
    "ax[i].plot(plot_data_generated[:num_test, 12], plot_data_generated[:num_test, 5]+0.05, '.r', alpha=.5, label=\"Generated\")\n",
    "ax[i].legend(loc='center right', fontsize=fontsize)\n",
    "plt.subplots_adjust(wspace=0.5)    \n",
    "            \n",
    "### d6 - label ###\n",
    "i = 6\n",
    "ax[i].clear()\n",
    "ax[i].set_xlim(list_limx[i])\n",
    "#ax[i].set_ylim(list_limy[i])\n",
    "ax[i].set_xlabel('d6 (mm)')\n",
    "ax[i].set_ylabel('label')                                    \n",
    "plot_data_real  = data_real.numpy()[:num_test, :]\n",
    "ax[i].plot(plot_data_real [:num_test, 12], plot_data_real [:num_test, 6], '.b', alpha=.5, label=\"Real\")\n",
    "ax[i].yaxis.set_major_locator(plt.MultipleLocator(base=1)) \n",
    "ax[i].yaxis.set_major_formatter('{:.0f}'.format)  \n",
    "plot_data_generated = dataframe_generated.values\n",
    "ax[i].plot(plot_data_generated[:num_test, 12], plot_data_generated[:num_test, 6]+0.05, '.r', alpha=.5, label=\"Generated\")\n",
    "ax[i].legend(loc='center right', fontsize=fontsize)\n",
    "\n",
    "\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9481cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['label1', 'label2', 'label3', 'label4', 'label5', 'label6','d1', 'd2', 'd3', 'd4', 'd5', 'd6', 'F','t']\n",
    "dataframe_generated.columns = names\n",
    "columns= ['label1', 'label2', 'label3', 'label4', 'label5', 'label6']\n",
    "dataframe_generated[columns] = dataframe_generated[columns].astype(int)\n",
    "dataframe_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd753274",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"X_generated_training \" + str(j) + \".csv\",dataframe_generated, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b108a42",
   "metadata": {},
   "source": [
    "# Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics: SSIM, (see reference Guan S. et al, Evaluation of GAN performance ...)\n",
    "\n",
    "# Calculate the SSIM between the two distributions, real and generated\n",
    "ssim_value = ssim(out, generated_out_final, multichannel=True)\n",
    "\n",
    "print('SSIM:', ssim_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce28cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics: Wasserstein distance (see reference Gulrajani I. et al, Improved training of Wasserstein gans ...)\n",
    "\n",
    "wasserstein_dist = wasserstein_distance(out.ravel(), generated_out_final.ravel())\n",
    "\n",
    "print(\"Waserstein distance of the generated dataset:\", wasserstein_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c52f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics: FID: Frechet Incepcion Distance (see reference Heusel M. et al, Gans trained by a two time-scale update rule converge ...)\n",
    "\n",
    "real_mean = np.mean(out, axis=0)\n",
    "real_covariance = np.cov(out, rowvar=False)\n",
    "\n",
    "fake_mean = np.mean(generated_out_final, axis=0)\n",
    "fake_covariance = np.cov(generated_out_final, rowvar=False)\n",
    "\n",
    "mean_difference = real_mean - fake_mean\n",
    "mean_difference_squared = np.dot(mean_difference, mean_difference)\n",
    "prod_covariance = real_covariance * fake_covariance\n",
    "\n",
    "covariance_sqrt, _ = scipy.linalg.sqrtm(prod_covariance, disp=False)\n",
    "if not np.isfinite(covariance_sqrt).all():\n",
    "    offset = np.eye(sum_covariance.shape[0]) * 1e-6\n",
    "    covariance_sqrt = scipy.linalg.sqrtm((prod_covariance + offset), disp=False)\n",
    "    \n",
    "fid1 = mean_difference_squared + np.trace(real_covariance + fake_covariance - 2 * covariance_sqrt)\n",
    "\n",
    "print(\"Frechet Inception Distance (FID):\", fid1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b87a1",
   "metadata": {},
   "source": [
    "# Visualization of the comparison between real data and training generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a2594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "F_train = dataframe['F']\n",
    "d6_train = dataframe['d6']\n",
    "t_train = dataframe['t']\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_title(\"Projection over the 3 axes od the TRAINING DATASET\")\n",
    "#ax.scatter(x_train,y_train,z_train, 'o')\n",
    "ax.set_xlabel('X axis = F (N)', fontsize='small')\n",
    "ax.set_ylabel('Y axis = d6 (m)', fontsize='small')\n",
    "ax.set_zlabel('Z axis = t (years)', fontsize='small')\n",
    "\n",
    "cx = np.ones_like(F_train) * ax.get_xlim3d()[0]\n",
    "cy = np.ones_like(d6_train) * ax.get_ylim3d()[0]\n",
    "cz = np.ones_like(t_train) * ax.get_zlim3d()[0]\n",
    "\n",
    "ax.scatter(F_train,  d6_train,  cz,               marker='.', lw=0,  color = \"blue\" , label= \"F (N)\")\n",
    "ax.scatter(F_train,  cy,       t_train,        marker='.', lw=0, alpha=0.05 , color =\"orange\", label = \"d6 (m)\")\n",
    "ax.scatter(cx,       d6_train,  t_train,         marker='.', lw=0,  color =\"green\", label =\"t (years)\")\n",
    "\n",
    "ax.set_xlim3d(ax.get_xlim3d())\n",
    "ax.set_ylim3d(ax.get_ylim3d())\n",
    "ax.set_zlim3d(ax.get_zlim3d())\n",
    "ax.set_xlabel('X axis = F (N)')\n",
    "ax.set_ylabel('Y axis = d6 (m)')\n",
    "ax.set_zlabel('Z axis = t (years)')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "\n",
    "F_predicted = dataframe_generated['F']\n",
    "d6_predicted = dataframe_generated['d6']\n",
    "t_predicted = dataframe_generated['t']\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_title(\"Projection over the 3 axes of the PREDICTED DATASET\")\n",
    "#ax.scatter(x_train,y_train,z_train, 'o')\n",
    "ax.set_xlabel('X axis = F (N)', fontsize='small')\n",
    "ax.set_ylabel('Y axis = d6 (m)', fontsize='small')\n",
    "ax.set_zlabel('Z axis = t (years)', fontsize='small')\n",
    "\n",
    "cx = np.ones_like(F_predicted) * ax.get_xlim3d()[0]\n",
    "cy = np.ones_like(d6_predicted) * ax.get_ylim3d()[0]\n",
    "cz = np.ones_like(t_predicted) * ax.get_zlim3d()[0]\n",
    "\n",
    "ax.scatter(F_predicted,  d6_predicted,  cz,               marker='.', lw=0,  color = \"blue\" , label= \"F (N)\")\n",
    "ax.scatter(F_predicted,  cy,       t_predicted,        marker='.', lw=0, alpha=0.05 , color =\"orange\", label = \"d6 (m)\")\n",
    "ax.scatter(cx,       d6_predicted,  t_predicted,         marker='.', lw=0,  color =\"green\", label =\"t (years)\")\n",
    "\n",
    "ax.set_xlim3d(ax.get_xlim3d())\n",
    "ax.set_ylim3d(ax.get_ylim3d())\n",
    "ax.set_zlim3d(ax.get_zlim3d())\n",
    "ax.set_xlabel('X axis = F (N)')\n",
    "ax.set_ylabel('Y axis = d6 (m)')\n",
    "ax.set_zlabel('Z axis = t (years)')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466c038a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16252f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTest= pd.read_excel('dataTest.xlsx', header=None)\n",
    "dataTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53078d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_test = dataTest.drop(dataTest.columns[:7], axis=1)\n",
    "condition_test = dataTest.drop(dataTest.columns[6:], axis=1)\n",
    "condition_test = condition_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([num_test, noise_dim], mean=0.0, stddev=0.1, dtype=tf.dtypes.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generated_out = generator([condition_test, noise], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b0208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generated_out_final = scaler.inverse_transform(test_generated_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e65b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_generated = np.concatenate([condition_test, test_generated_out_final], axis=1)\n",
    "df_data_generated=pd.DataFrame(plot_data_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb810a59",
   "metadata": {},
   "source": [
    "# Testing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90703db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics: Wasserstein distance\n",
    "wasserstein_dist = wasserstein_distance(out_test.ravel(), test_generated_out_final.ravel())\n",
    "\n",
    "print(\"Waserstein distance of the generated dataset:\", wasserstein_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01397713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics: FID\n",
    "real_mean = np.mean(out_test, axis=0)\n",
    "real_covariance = np.cov(out_test, rowvar=False)\n",
    "\n",
    "fake_mean = np.mean(test_generated_out_final, axis=0)\n",
    "fake_covariance = np.cov(test_generated_out_final, rowvar=False)\n",
    "\n",
    "mean_difference = real_mean - fake_mean\n",
    "mean_difference_squared = np.dot(mean_difference, mean_difference)\n",
    "prod_covariance = real_covariance * fake_covariance\n",
    "\n",
    "covariance_sqrt, _ = scipy.linalg.sqrtm(prod_covariance, disp=False)\n",
    "if not np.isfinite(covariance_sqrt).all():\n",
    "    offset = np.eye(sum_covariance.shape[0]) * 1e-6\n",
    "    covariance_sqrt = scipy.linalg.sqrtm((prod_covariance + offset), disp=False)\n",
    "    \n",
    "fid1 = mean_difference_squared + np.trace(real_covariance + fake_covariance - 2 * covariance_sqrt)\n",
    "\n",
    "print(\"Frechet Inception Distance (FID):\", fid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf2df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics: SSIM\n",
    "ssim_value = ssim(out_test, test_generated_out_final, multichannel=True)\n",
    "\n",
    "print('SSIM:', ssim_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce514aa7",
   "metadata": {},
   "source": [
    "# Visualization of the comparison between real data and testing generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f1085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "\n",
    "figure, ax = plt.subplots(1, 4, figsize=(15, 3))\n",
    "figure.suptitle(\"Conditional GAN (WCGAN-GP)\")\n",
    "sns.set(color_codes=True, style='white', palette='colorblind')\n",
    "          \n",
    "### d6 - t  ###\n",
    "i = 0\n",
    "ax[i].clear()\n",
    "ax[i].set_xlabel('d6 (mm)')\n",
    "ax[i].set_ylabel('t (years)')\n",
    "plot_data_real = dataTest               \n",
    "ax[i].plot(plot_data_real[ 12], plot_data_real[ 14], '.b', alpha=1, label=\"Test\")\n",
    "ax[i].plot(plot_data_generated[:num_test, 12], plot_data_generated[:num_test, 14], '.r', alpha=1, label=\"Generated\")\n",
    "ax[i].legend(loc='lower right')  \n",
    "                                  \n",
    "            \n",
    "###  d6 - F  ###\n",
    "i = 1\n",
    "ax[i].clear()\n",
    "ax[i].set_xlabel('d6 (mm)')\n",
    "ax[i].set_ylabel('F (N)')\n",
    "ax[i].plot(plot_data_real [ 12], plot_data_real [ 13], '.b', alpha=1, label=\"Test\")\n",
    "ax[i].plot(plot_data_generated[:num_test, 12], plot_data_generated[:num_test, 13], '.r', alpha=1, label=\"Generated\")\n",
    "ax[i].legend(loc='lower right')\n",
    "            \n",
    "### d6 - label ###\n",
    "i = 2\n",
    "ax[i].clear()\n",
    "ax[i].set_xlabel('d6 (mm)')\n",
    "ax[i].set_ylabel('label')\n",
    "ax[i].plot(plot_data_real [ 12], plot_data_real [ 6], '.b', alpha=1, label=\"Test\")\n",
    "ax[i].yaxis.set_major_locator(plt.MultipleLocator(base=1)) \n",
    "ax[i].yaxis.set_major_formatter('{:.0f}'.format)  \n",
    "ax[i].plot(plot_data_generated[:num_test, 12], plot_data_generated[:num_test, 6]+0.05, '.r', alpha=1, label=\"Generated\")\n",
    "ax[i].legend(loc='center right')\n",
    "\n",
    "\n",
    "### d6  -  label6  ###\n",
    "i = 3\n",
    "ax[i].clear()\n",
    "ax[i].set_xlabel('d6 (mm)')\n",
    "ax[i].set_ylabel('label6')\n",
    "ax[i].plot(plot_data_real[ 12], plot_data_real[ 5], '.b', alpha=1, label=\"Real\")\n",
    "ax[i].yaxis.set_major_locator(plt.MultipleLocator(base=1)) \n",
    "ax[i].yaxis.set_major_formatter('{:.0f}'.format)  \n",
    "ax[i].plot(plot_data_generated[:num_test, 12], plot_data_generated[:num_test, 5]+0.05, '.r', alpha=1, label=\"Generated\")\n",
    "ax[i].legend(loc='center right')\n",
    "plt.subplots_adjust(wspace=0.5)    \n",
    "\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45701d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_title(\"Projection over the 3 axes\")\n",
    "#ax.scatter(x_train,y_train,z_train, 'o')\n",
    "ax.set_xlabel('X axis = F (N)', fontsize='small')\n",
    "ax.set_ylabel('Y axis = d6 (m)', fontsize='small')\n",
    "ax.set_zlabel('Z axis = t (years)', fontsize='small')\n",
    "\n",
    "cx = np.ones_like(F_predicted) * ax.get_xlim3d()[0]\n",
    "cy = np.ones_like(d6_predicted) * ax.get_ylim3d()[0]\n",
    "cz = np.ones_like(t_predicted) * ax.get_zlim3d()[0]\n",
    "\n",
    "ax.scatter(F_predicted,  d6_predicted,  cz,               marker='.', lw=0,  color = \"blue\" , label= \"F (N)\")\n",
    "ax.scatter(F_predicted,  cy,       t_predicted,        marker='.', lw=0, alpha=0.5 , color =\"orange\", label = \"d6 (m)\")\n",
    "ax.scatter(cx,       d6_predicted,  t_predicted,         marker='.', lw=0,  color =\"green\", label =\"t (years)\")\n",
    "\n",
    "ax.set_xlim3d(ax.get_xlim3d())\n",
    "ax.set_ylim3d(ax.get_ylim3d())\n",
    "ax.set_zlim3d(ax.get_zlim3d())\n",
    "ax.set_xlabel('X axis = F (N)')\n",
    "ax.set_ylabel('Y axis = d6 (m)')\n",
    "ax.set_zlabel('Z axis = t (years)')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
